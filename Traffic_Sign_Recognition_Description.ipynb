{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1gH-47Y09A2Xx_o9p1k5Rn9L_n6h9eqDp",
      "authorship_tag": "ABX9TyNj+vwAN0PT02TbO0yibSId",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maramatef111/Elevvo-Internship-Tasks/blob/main/Traffic_Sign_Recognition_Description.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "U3h3tLIicVlV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam , Adamax\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Flatten, Dense, Activation, Dropout ,Conv2D,MaxPool2D,GlobalAveragePooling2D,BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from PIL import Image\n",
        "import csv\n",
        "import cv2\n",
        "\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.models import load_model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = '/content/drive/MyDrive/Traffic_Sign_Recognition _Description'\n",
        "images = [] # images\n",
        "labels = [] # corresponding labels\n",
        "\n",
        "# loop over all 43 classes\n",
        "gtFile = open(PATH + '/Train.csv') # annotations file\n",
        "gtReader = csv.reader(gtFile, delimiter=',') # csv parser for annotations file\n",
        "next(gtReader) # skip header\n",
        "# loop over all images in current annotations file\n",
        "for row in gtReader:\n",
        "    img = cv2.imread(PATH + '/' + row[7])\n",
        "    if img is not None:\n",
        "        images.append(cv2.resize(img, (28, 28)))\n",
        "        labels.append(row[6]) # the 6th column is the label\n",
        "gtFile.close()"
      ],
      "metadata": {
        "id": "TIJ659fLdrk8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "yGLKAtIhPjsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Number of loaded images: ' + str(len(images)))\n",
        "print('Number of loaded labels: ' + str(len(labels)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlhI1Oy1drhj",
        "outputId": "587e8bc9-8db2-4953-e4e1-cb5be3e67ddc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of loaded images: 5259\n",
            "Number of loaded labels: 5259\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images = np.asarray(images)\n",
        "images = images / 255\n",
        "images = np.asarray(images, dtype = \"float32\")\n",
        "labels = np.asarray(labels, dtype= \"int32\")"
      ],
      "metadata": {
        "id": "cSBcYdi9dreA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Shape of training array: ' + str(images.shape))"
      ],
      "metadata": {
        "id": "pz5Q2-mNdraz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,8))\n",
        "sns.countplot(x=labels,palette='viridis')\n",
        "plt.title('The Count of images in training data')\n",
        "plt.xlabel('labels')\n",
        "plt.ylabel('count')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1IJA8JfDdrXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preview(images, labels):\n",
        "    plt.figure(figsize=(16, 16))\n",
        "    for c in range(len(np.unique(labels))):\n",
        "        i = np.random.choice(np.where(labels == c)[0])\n",
        "        plt.subplot(10, 10, c+1)\n",
        "        plt.axis('off')\n",
        "        plt.title('class: {}'.format(c))\n",
        "        plt.imshow(images[i])\n",
        "preview(images, labels)"
      ],
      "metadata": {
        "id": "WlUSstxBf8ml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# New desired size\n",
        "new_size = (32, 32)\n",
        "\n",
        "# Resize all images\n",
        "images = np.array([cv2.resize(img, new_size) for img in images])\n",
        "\n",
        "print('Shape of resized array:', images.shape)"
      ],
      "metadata": {
        "id": "fDostFsAf8f4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = np.array([0, 1, 0, 2, 1])\n",
        "np.where(labels == 1)\n",
        "# Output: (array([1, 4]),)  ← tuple with one array\n",
        "\n",
        "print(result)       # (array([1, 4]),)\n",
        "print(result[0])    # array([1, 4])"
      ],
      "metadata": {
        "id": "0Cj6vzjtf8ci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preview(images, labels):\n",
        "    # Create a new figure with a specified size (16 inches by 16 inches)\n",
        "    plt.figure(figsize=(16, 16))\n",
        "\n",
        "    # Loop through each unique class label\n",
        "    for c in range(len(np.unique(labels))):\n",
        "        # Randomly choose one index of an image belonging to the current class 'c'\n",
        "        i = np.random.choice(np.where(labels == c)[0])\n",
        "\n",
        "        # Create a subplot (10 rows × 10 columns), placing the image in position (c+1)\n",
        "        plt.subplot(10, 10, c + 1)\n",
        "\n",
        "        # Hide the axis (no ticks, no border)\n",
        "        plt.axis('off')\n",
        "         # Set the title of this subplot to show the class number\n",
        "        plt.title('class: {}'.format(c))\n",
        "\n",
        "        # Display the selected image\n",
        "        plt.imshow(images[i])\n",
        "\n",
        "# Call the function to preview one sample image from each class\n",
        "preview(images, labels)\n"
      ],
      "metadata": {
        "id": "Ysm1Qbo2f8Zz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split Data"
      ],
      "metadata": {
        "id": "YCDg-7Lugyai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    images, labels,\n",
        "    test_size=0.2,   # 20% for validation\n",
        "    stratify=labels,  # keep class balance\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"Train:\", X_train.shape, \"Validation:\", X_val.shape)"
      ],
      "metadata": {
        "id": "yVm4Z6kWgkYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Augmentation"
      ],
      "metadata": {
        "id": "XpNALueyg4A3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rotation_range=10,\n",
        "    zoom_range=0.15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.15,\n",
        "    horizontal_flip=False,\n",
        "    vertical_flip=False,\n",
        "    fill_mode=\"nearest\"\n",
        ")\n",
        "\n",
        "# Validation data (no augmentation, no rescale)\n",
        "val_datagen = ImageDataGenerator()\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# One-hot encode labels\n",
        "y_train_cat = to_categorical(y_train, num_classes=43)\n",
        "y_val_cat = to_categorical(y_val, num_classes=43)\n",
        "\n",
        "# Now flow with the encoded labels\n",
        "train_generator = train_datagen.flow(X_train, y_train_cat, batch_size=32, shuffle=True)\n",
        "val_generator = val_datagen.flow(X_val, y_val_cat, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "pg3L6EX6gkRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(np.unique(y_train))                               # infer how many classes you have\n",
        "input_shape = X_train.shape[1:]"
      ],
      "metadata": {
        "id": "TE-ivKvFgkJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape"
      ],
      "metadata": {
        "id": "7DAWp5cUgkFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Custom_CNN"
      ],
      "metadata": {
        "id": "QZPe4KGkhP7N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(filters=16, kernel_size=(3,3), activation='relu', input_shape=input_shape))\n",
        "model.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(BatchNormalization(axis=-1))\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(BatchNormalization(axis=-1))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(BatchNormalization(axis=-1))\n",
        "model.add(Dropout(rate=0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))"
      ],
      "metadata": {
        "id": "38DxsffvhLNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "PBvuUIF9hLKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(Adam(learning_rate= 0.001), loss='categorical_crossentropy'\n",
        ", metrics= ['accuracy'])"
      ],
      "metadata": {
        "id": "DhQhV9RohLG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    EarlyStopping(\n",
        "        patience=7,\n",
        "        restore_best_weights=True,\n",
        "        monitor='val_accuracy'\n",
        "    ),\n",
        "    ReduceLROnPlateau(\n",
        "        patience=3,\n",
        "        factor=0.5,\n",
        "        min_lr=1e-5,\n",
        "        monitor='val_loss'\n",
        "    ),\n",
        "    ModelCheckpoint(\n",
        "        filepath='best_gtsrb_cnn.keras',\n",
        "        save_best_only=True,\n",
        "        monitor='val_accuracy'\n",
        "    )\n",
        "]"
      ],
      "metadata": {
        "id": "tfW9fz_-hK5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_generator,                                                       # augmented training data\n",
        "    validation_data=val_generator,                                         # clean validation data\n",
        "    epochs=10,                                                       # cap epochs; early stopping will trigger\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "mu6UAxCfhK1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_loss, val_acc = model.evaluate(val_generator, verbose=0)\n",
        "print(f\"Validation accuracy: {val_acc:.4f}\")"
      ],
      "metadata": {
        "id": "jJSFVrImh4j8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get true labels from the generator (one-hot encoded -> convert to class indices)\n",
        "y_val_true = np.argmax(val_generator.y, axis=1)\n",
        "\n",
        "\n",
        "val_steps = len(val_generator)   # number of batches in the generator\n",
        "\n",
        "\n",
        "# predictions\n",
        "y_val_pred_probs = model.predict(val_generator, steps=val_steps, verbose=1)\n",
        "y_val_pred = np.argmax(y_val_pred_probs, axis=1)\n",
        "\n",
        "# confusion matrix\n",
        "cm = confusion_matrix(y_val_true, y_val_pred)\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(cm, annot=True, cmap=\"Blues\", fmt='g')\n",
        "plt.title(\"Confusion Matrix (Validation Set)\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.show()\n",
        "\n",
        "# classification report\n",
        "print(classification_report(y_val_true, y_val_pred))"
      ],
      "metadata": {
        "id": "NI9EZ6Thh4gg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pre_Trained model"
      ],
      "metadata": {
        "id": "_5j6L6SPiymg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load base model\n",
        "base_model = MobileNetV2(\n",
        "    weights='imagenet',\n",
        "    include_top=False,\n",
        "    input_shape=(32, 32, 3)\n",
        ")\n",
        "base_model.trainable = False  # Freeze base layers\n",
        "\n",
        "# Add custom classification head\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "predictions = Dense(43, activation='softmax')(x)\n",
        "\n",
        "mobilenet_model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "mobilenet_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "# Train MobileNetV2\n",
        "checkpoint_mobilenet = ModelCheckpoint('best_mobilenet.keras', save_best_only=True, monitor='val_accuracy', mode='max')\n",
        "\n",
        "history_mobilenet = mobilenet_model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=10,\n",
        "    callbacks=[checkpoint_mobilenet]\n",
        ")"
      ],
      "metadata": {
        "id": "h21UR8sUh4du"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "model.save(f\"/kaggle/working/best_mobilenet_{datetime.now().strftime('%Y%m%d_%H%M%S')}.keras\")"
      ],
      "metadata": {
        "id": "qZBYvGsIh4bg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compare between Custom CNN and Pre-trained Model"
      ],
      "metadata": {
        "id": "84Mo_FHLjOBb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions for Custom CNN\n",
        "custom_preds = model.predict(val_generator)\n",
        "custom_preds_classes = np.argmax(custom_preds, axis=1)\n",
        "true_classes = np.argmax(y_val_cat, axis=1)\n",
        "\n",
        "# Predictions for MobileNet\n",
        "mobilenet_preds = mobilenet_model.predict(val_generator)\n",
        "mobilenet_preds_classes = np.argmax(mobilenet_preds, axis=1)\n",
        "\n",
        "# Confusion matrix for Custom CNN\n",
        "cm_cnn = confusion_matrix(true_classes, custom_preds_classes)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm_cnn, annot=False, cmap=\"Blues\")\n",
        "plt.title(\"Custom CNN Confusion Matrix\")\n",
        "plt.show()\n",
        "# Confusion matrix for MobileNet\n",
        "cm_mobile = confusion_matrix(true_classes, mobilenet_preds_classes)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm_mobile, annot=False, cmap=\"Greens\")\n",
        "plt.title(\"MobileNet Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "# Classification report\n",
        "print(\"Custom CNN Report:\\n\", classification_report(true_classes, custom_preds_classes))\n",
        "print(\"MobileNet Report:\\n\", classification_report(true_classes, mobilenet_preds_classes))"
      ],
      "metadata": {
        "id": "NSN9pw-TjGPm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GTSRB Test Evaluation Script"
      ],
      "metadata": {
        "id": "KC3ezA8jtMd5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "# Paths - make sure these are correct\n",
        "PATH = \"/content/drive/MyDrive/Traffic_Sign_Recognition _Description\"  # Adjust this path\n",
        "data_dir = \"/content/drive/MyDrive/Traffic_Sign_Recognition _Description\"  # Adjust this path\n",
        "\n",
        "test = pd.read_csv(os.path.join(PATH, 'Test.csv'))\n",
        "\n",
        "labels = test[\"ClassId\"].values\n",
        "imgs = test[\"Path\"].values\n",
        "\n",
        "print(f\"Total images in CSV: {len(imgs)}\")\n",
        "\n",
        "# Preprocess test images (32x32 for both models)\n",
        "data = []\n",
        "successful_indices = []  # To keep track of which images loaded successfully\n",
        "successful_labels = []   # Corresponding labels for successful images\n",
        "\n",
        "for i, img_path in enumerate(imgs):\n",
        "   try:\n",
        "        # Construct full path\n",
        "        full_img_path = os.path.join(data_dir, img_path)\n",
        "\n",
        "        # Check if file exists\n",
        "        if not os.path.exists(full_img_path):\n",
        "            print(f\"File not found: {full_img_path}\")\n",
        "            continue\n",
        "\n",
        "        image = cv2.imread(full_img_path)\n",
        "\n",
        "        # Check if image was loaded correctly\n",
        "        if image is None:\n",
        "            print(f\"Failed to load image: {img_path}\")\n",
        "            continue\n",
        "\n",
        "        image_fromarray = Image.fromarray(image, 'RGB')\n",
        "        resize_image = image_fromarray.resize((32, 32))\n",
        "        data.append(np.array(resize_image))\n",
        "        successful_indices.append(i)\n",
        "        successful_labels.append(labels[i])\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in {img_path}: {str(e)}\")\n",
        "\n",
        "# Check if any images were loaded\n",
        "if len(data) == 0:\n",
        "    print(\"❌ No images were loaded successfully! Check your file paths.\")\n",
        "    print(\"Available files in data_dir:\")\n",
        "    try:\n",
        "        files = os.listdir(data_dir)\n",
        "        print(f\"First 10 files: {files[:10]}\")\n",
        "    except:\n",
        "        print(\"Cannot list directory - path might be wrong\")\n",
        "else:\n",
        "    X_test = np.array(data)\n",
        "    X_test = X_test / 255.0   # normalization\n",
        "\n",
        "    # ✅ Keep the data as images (32, 32, 3)\n",
        "    print(f\"X_test shape: {X_test.shape}\")\n",
        "     print(f\"Successfully loaded {X_test.shape[0]} out of {len(imgs)} images\")\n",
        "\n",
        "    # Filter labels to only include successful images\n",
        "    filtered_labels = np.array(successful_labels)\n",
        "\n",
        "    # Predictions with both models using the same preprocessed data\n",
        "    print(\"Making predictions with Custom Model...\")\n",
        "    y_pred_probs_custom = model.predict(X_test, batch_size=32, verbose=1)\n",
        "    pred_custom = np.argmax(y_pred_probs_custom, axis=1)\n",
        "\n",
        "    print(\"Making predictions with MobileNet Model...\")\n",
        "    y_pred_probs_mobilenet = mobilenet_model.predict(X_test, batch_size=32, verbose=1)\n",
        "    pred_mobilenet = np.argmax(y_pred_probs_mobilenet, axis=1)\n",
        "\n",
        "    # Accuracy for both models\n",
        "    custom_accuracy = accuracy_score(filtered_labels, pred_custom) * 100\n",
        "    mobilenet_accuracy = accuracy_score(filtered_labels, pred_mobilenet) * 100\n",
        "\n",
        "    print('Custom Model Test Accuracy: ', custom_accuracy)\n",
        "    print('MobileNet Test Accuracy: ', mobilenet_accuracy)\n"
      ],
      "metadata": {
        "id": "QIz3FcCijGMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Select 10 random indices - CORRECTED LINE\n",
        "random_indices = np.random.choice(range(len(X_test)), 10, replace=False)\n",
        "\n",
        "# Create a figure to display the results\n",
        "plt.figure(figsize=(20, 12))\n",
        "\n",
        "for i, idx in enumerate(random_indices):\n",
        "    # Get the image and true label\n",
        "    image = X_test[idx]\n",
        "    true_label = labels[idx]\n",
        "\n",
        "    # Get predictions from both models\n",
        "    custom_pred = pred_custom[idx]\n",
        "    mobilenet_pred = pred_mobilenet[idx]\n",
        "\n",
        "    # Check if predictions are correct\n",
        "    custom_correct = (custom_pred == true_label)\n",
        "    mobilenet_correct = (mobilenet_pred == true_label)\n",
        "\n",
        "    # Create subplot\n",
        "    plt.subplot(2, 5, i+1)\n",
        "\n",
        "    # Display the image\n",
        "    plt.imshow(image)\n",
        "\n",
        "    # Set title with prediction results\n",
        "    title = f'True: {true_label}\\n'\n",
        "    title += f'Custom: {custom_pred} '\n",
        "    title += '✓' if custom_correct else '✗'\n",
        "    title += f'\\nMobileNet: {mobilenet_pred} '\n",
        "    title += '✓' if mobilenet_correct else '✗'\n",
        "\n",
        "    # Color code: green for correct, red for wrong\n",
        "    color = 'green' if (custom_correct and mobilenet_correct) else 'red'\n",
        "\n",
        "    plt.title(title, color=color, fontsize=10)\n",
        "    plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.suptitle('Predictions on 10 Random Images\\n(✓ = Correct, ✗ = Wrong)', fontsize=16, y=1.02)\n",
        "plt.show()\n",
        "\n",
        "# Print detailed results\n",
        "print(\"Detailed Results for 10 Random Images:\")\n",
        "print(\"=\" * 50)\n",
        "for i, idx in enumerate(random_indices):\n",
        "    true_label = labels[idx]\n",
        "    custom_pred = pred_custom[idx]\n",
        "    mobilenet_pred = pred_mobilenet[idx]\n",
        "\n",
        "    custom_status = \"CORRECT\" if custom_pred == true_label else \"WRONG\"\n",
        "    mobilenet_status = \"CORRECT\" if mobilenet_pred == true_label else \"WRONG\"\n",
        "\n",
        "    print(f\"Image {i+1}: True Label = {true_label}\")\n",
        "    print(f\"  Custom Model: {custom_pred} ({custom_status})\")\n",
        "    print(f\"  MobileNet: {mobilenet_pred} ({mobilenet_status})\")\n",
        "    print(\"-\" * 30)\n",
        "    # Calculate agreement between models\n",
        "agreement_count = sum(1 for i in range(len(labels)) if pred_custom[i] == pred_mobilenet[i])\n",
        "agreement_percentage = (agreement_count / len(labels)) * 100\n",
        "\n",
        "print(f\"\\nModel Agreement: {agreement_percentage:.2f}% of predictions are the same\")\n",
        "print(f\"Custom Model Accuracy: {custom_accuracy:.2f}%\")\n",
        "print(f\"MobileNet Accuracy: {mobilenet_accuracy:.2f}%\")"
      ],
      "metadata": {
        "id": "92N88NFEjGJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9K6OmhRUjGHP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}